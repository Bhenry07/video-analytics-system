{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c982a848",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# YOLOv8 Training - Banking Detection Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"Train a custom object detection model on your exported dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Instructions:**\\n\",\n",
    "    \"1. Click Runtime > Change runtime type > Select GPU (T4 is free!)\\n\",\n",
    "    \"2. Upload your banking_dataset zip file when prompted\\n\",\n",
    "    \"3. Run all cells in order\\n\",\n",
    "    \"4. Download trained model when complete\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add60a5c",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ae1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "print(f\"‚úÖ Ultralytics installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d392e",
   "metadata": {},
   "source": [
    "## üì§ Step 2: Upload Your Dataset ZIP\n",
    "\n",
    "Click the upload button and select your `banking_dataset_*.zip` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e57953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì§ Click 'Choose Files' and upload your banking_dataset_*.zip\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded ZIP filename\n",
    "zip_filename = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {zip_filename}\")\n",
    "print(f\"   Size: {len(uploaded[zip_filename]) / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f56262",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Step 3: Prepare Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "print(\"üöÄ Preparing dataset...\")\n",
    "\n",
    "# Create directories\n",
    "base_path = Path('dataset')\n",
    "dirs = {\n",
    "    'train_images': base_path / 'images' / 'train',\n",
    "    'train_labels': base_path / 'labels' / 'train',\n",
    "    'val_images': base_path / 'images' / 'val',\n",
    "    'val_labels': base_path / 'labels' / 'val',\n",
    "    'test_images': base_path / 'images' / 'test',\n",
    "    'test_labels': base_path / 'labels' / 'test',\n",
    "}\n",
    "\n",
    "for dir_path in dirs.values():\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Created directory structure\")\n",
    "\n",
    "# Extract ZIP\n",
    "temp_extract = Path('temp_extract')\n",
    "temp_extract.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üì¶ Extracting {zip_filename}...\")\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_extract)\n",
    "\n",
    "# Find extracted folders\n",
    "images_dir = temp_extract / 'images'\n",
    "annotations_dir = temp_extract / 'annotations'\n",
    "\n",
    "# Get all image files\n",
    "image_files = list(images_dir.glob('*.jpg'))\n",
    "print(f\"üì∏ Found {len(image_files)} images\")\n",
    "\n",
    "# Shuffle and split (80/15/5)\n",
    "random.seed(42)\n",
    "random.shuffle(image_files)\n",
    "\n",
    "total = len(image_files)\n",
    "train_split = int(0.8 * total)\n",
    "val_split = int(0.95 * total)\n",
    "\n",
    "train_files = image_files[:train_split]\n",
    "val_files = image_files[train_split:val_split]\n",
    "test_files = image_files[val_split:]\n",
    "\n",
    "print(f\"üìä Split: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test\")\n",
    "\n",
    "# Copy files\n",
    "def copy_split(files, img_dir, label_dir):\n",
    "    for img_file in files:\n",
    "        shutil.copy2(img_file, img_dir / img_file.name)\n",
    "        label_file = annotations_dir / img_file.with_suffix('.txt').name\n",
    "        if label_file.exists():\n",
    "            shutil.copy2(label_file, label_dir / label_file.name)\n",
    "\n",
    "print(\"üìÇ Copying files...\")\n",
    "copy_split(train_files, dirs['train_images'], dirs['train_labels'])\n",
    "copy_split(val_files, dirs['val_images'], dirs['val_labels'])\n",
    "copy_split(test_files, dirs['test_images'], dirs['test_labels'])\n",
    "\n",
    "# Read class names\n",
    "classes_file = temp_extract / 'classes.txt'\n",
    "if classes_file.exists():\n",
    "    with open(classes_file, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "else:\n",
    "    class_names = ['person', 'car', 'truck', 'handbag', 'backpack', 'bottle', 'cell phone']\n",
    "\n",
    "print(f\"üè∑Ô∏è  Classes: {', '.join(class_names)}\")\n",
    "\n",
    "# Create dataset.yaml\n",
    "yaml_content = f\"\"\"path: /content/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "\"\"\"\n",
    "\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    yaml_content += f\"  {idx}: {class_name}\\n\"\n",
    "\n",
    "yaml_path = base_path / 'dataset.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"‚úÖ Created {yaml_path}\")\n",
    "\n",
    "# Clean up\n",
    "shutil.rmtree(temp_extract)\n",
    "os.remove(zip_filename)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® Dataset preparation complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ Dataset location: {base_path.absolute()}\")\n",
    "print(f\"üìä Total: {total} images\")\n",
    "print(f\"üè∑Ô∏è  Classes: {len(class_names)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb1482",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Train YOLOv8 Model\n",
    "\n",
    "**Model sizes:**\n",
    "- `yolov8n.pt` - Nano (fastest, ~2M params)\n",
    "- `yolov8s.pt` - Small (balanced, ~9M params) ‚≠ê **Recommended**\n",
    "- `yolov8m.pt` - Medium (~20M params)\n",
    "- `yolov8l.pt` - Large (~43M params)\n",
    "\n",
    "Training takes ~15-30 minutes with free GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "MODEL_SIZE = 's'  # Change to 'n', 'm', or 'l' if desired\n",
    "EPOCHS = 100       # Number of training epochs\n",
    "BATCH_SIZE = 16    # Batch size (reduce if out of memory)\n",
    "IMG_SIZE = 640     # Input image size\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "print(f\"   Model: YOLOv8{MODEL_SIZE.upper()}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Device: GPU ({torch.cuda.get_device_name(0)})\")\n",
    "print(f\"\\n‚è±Ô∏è  Estimated time: ~{EPOCHS * 0.2:.0f} minutes\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üé¨ Starting training...\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1298346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = YOLO(f'yolov8{MODEL_SIZE}.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='dataset/dataset.yaml',\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    device=0,\n",
    "    project='runs/train',\n",
    "    name='banking_detection',\n",
    "    pretrained=True,\n",
    "    optimizer='auto',\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    patience=50,\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    amp=True,\n",
    "    # Data augmentation\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383b50d",
   "metadata": {},
   "source": [
    "## üìä Step 5: Validate Model & View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"üìä Running validation...\")\n",
    "metrics = model.val()\n",
    "\n",
    "print(f\"\\nüéØ Results:\")\n",
    "print(f\"   mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"   mAP50-95: {metrics.box.map:.3f}\")\n",
    "print(f\"   Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"   Recall: {metrics.box.mr:.3f}\")\n",
    "\n",
    "# Display training results\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"\\nüìà Training Results:\")\n",
    "\n",
    "results_dir = Path('runs/train/banking_detection')\n",
    "\n",
    "# Show confusion matrix\n",
    "if (results_dir / 'confusion_matrix.png').exists():\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    display(Image(filename=str(results_dir / 'confusion_matrix.png')))\n",
    "\n",
    "# Show results curves\n",
    "if (results_dir / 'results.png').exists():\n",
    "    print(\"\\nTraining Curves:\")\n",
    "    display(Image(filename=str(results_dir / 'results.png')))\n",
    "\n",
    "# Show sample predictions\n",
    "if (results_dir / 'val_batch0_pred.jpg').exists():\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    display(Image(filename=str(results_dir / 'val_batch0_pred.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8b8ae",
   "metadata": {},
   "source": [
    "## üß™ Step 6: Test Model on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO('runs/train/banking_detection/weights/best.pt')\n",
    "\n",
    "# Get a random test image\n",
    "test_images = list(Path('dataset/images/test').glob('*.jpg'))\n",
    "if test_images:\n",
    "    test_img = random.choice(test_images)\n",
    "    \n",
    "    print(f\"üß™ Testing on: {test_img.name}\")\n",
    "    \n",
    "    # Run inference\n",
    "    results = best_model(test_img)\n",
    "    \n",
    "    # Display results\n",
    "    for result in results:\n",
    "        result_img = result.plot()\n",
    "        import cv2\n",
    "        from matplotlib import pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Model Prediction')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detections\n",
    "        boxes = result.boxes\n",
    "        if len(boxes) > 0:\n",
    "            print(f\"\\n‚úÖ Found {len(boxes)} objects:\")\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                print(f\"   - {result.names[cls]}: {conf:.2%}\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No objects detected in this image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec4ff1",
   "metadata": {},
   "source": [
    "## üì• Step 7: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c83e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ZIP with model and results\n",
    "import shutil\n",
    "\n",
    "print(\"üì¶ Packaging model for download...\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('trained_model')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy model files\n",
    "weights_dir = Path('runs/train/banking_detection/weights')\n",
    "shutil.copy2(weights_dir / 'best.pt', output_dir / 'banking_model_best.pt')\n",
    "shutil.copy2(weights_dir / 'last.pt', output_dir / 'banking_model_last.pt')\n",
    "\n",
    "# Copy results\n",
    "results_dir = Path('runs/train/banking_detection')\n",
    "for img_file in ['confusion_matrix.png', 'results.png', 'val_batch0_pred.jpg']:\n",
    "    src = results_dir / img_file\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, output_dir / img_file)\n",
    "\n",
    "# Create README\n",
    "readme = f\"\"\"# Banking Detection Model\n",
    "\n",
    "Trained: {pd.Timestamp.now()}\n",
    "\n",
    "## Model Details\n",
    "- Architecture: YOLOv8{MODEL_SIZE.upper()}\n",
    "- Training epochs: {EPOCHS}\n",
    "- mAP50: {metrics.box.map50:.3f}\n",
    "- mAP50-95: {metrics.box.map:.3f}\n",
    "\n",
    "## Files\n",
    "- `banking_model_best.pt` - Best model checkpoint (use this!)\n",
    "- `banking_model_last.pt` - Last epoch checkpoint\n",
    "- `confusion_matrix.png` - Model performance visualization\n",
    "- `results.png` - Training curves\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('banking_model_best.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model('image.jpg')\n",
    "\n",
    "# Process results\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    for box in boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        print(f\"{{result.names[cls]}}: {{conf:.2%}}\")\n",
    "```\n",
    "\n",
    "## Classes\n",
    "{chr(10).join([f\"{i}. {name}\" for i, name in enumerate(class_names)])}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / 'README.md', 'w') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "# Create ZIP\n",
    "import pandas as pd\n",
    "shutil.make_archive('banking_model', 'zip', output_dir)\n",
    "\n",
    "print(\"‚úÖ Model packaged successfully!\")\n",
    "print(\"\\nüì• Downloading...\")\n",
    "\n",
    "# Download\n",
    "files.download('banking_model.zip')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Training complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüì¶ Downloaded: banking_model.zip\")\n",
    "print(\"\\nüí° Next steps:\")\n",
    "print(\"   1. Extract the ZIP file\")\n",
    "print(\"   2. Use 'banking_model_best.pt' in your app\")\n",
    "print(\"   3. Replace COCO-SSD with this custom model\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458dbf31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Extract downloaded ZIP**\n",
    "2. **Integrate model into your app** - I'll help you replace COCO-SSD with your custom model\n",
    "3. **Test on real ATM videos** - See improved detection!\n",
    "\n",
    "Your custom model is now trained specifically on ATM/banking footage and will perform much better than the generic COCO-SSD model! üéØ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
